{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gVj8elM_D-q"
      },
      "source": [
        "# Set the Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8l6iBsU-ygg"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0pqN6usE-fpx"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2ForXVector, WavLMForXVector\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, f1_score, roc_auc_score\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn import tree\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEIBU1Ac-oLd",
        "outputId": "86021102-bf4e-4b29-9c0e-e881b8819b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2QkiVBw-goX",
        "outputId": "0ceca7ac-78b5-4d43-e0a9-af683402111d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_JzbiJ-_IN8"
      },
      "source": [
        "# Upload pretrained WavLMforXVectors Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhiiDdcc-ief"
      },
      "outputs": [],
      "source": [
        "# feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"anton-l/wav2vec2-base-superb-sv\")\n",
        "# model = Wav2Vec2ForXVector.from_pretrained(\"anton-l/wav2vec2-base-superb-sv\").cuda()\n",
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"microsoft/wavlm-base-plus-sv\")\n",
        "model = WavLMForXVector.from_pretrained(\"microsoft/wavlm-base-plus-sv\").cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVSmzBr2_Qx3"
      },
      "source": [
        "# Embeddings Extraction "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kXnTdjqLQZs"
      },
      "source": [
        "## Loading Audios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBAXJPC3_ZGt",
        "outputId": "ebcfc9d4-297e-4c9c-e0e8-49d503901ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audios correctly loaded\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/mosquito/'\n",
        "audio_train = glob.glob(path + 'train/*.wav')\n",
        "audio_dev = glob.glob(path + 'dev/a/*.wav')\n",
        "print(\"Audios correctly loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJDTaiihQu58",
        "outputId": "9e25a44e-5348-42db-89e1-a7d9fb010702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8196\n",
            "2165\n"
          ]
        }
      ],
      "source": [
        "print(len(audio_train))\n",
        "print(len(audio_dev))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_QoJrUoWJ-Or"
      },
      "outputs": [],
      "source": [
        "max_duration = 30.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am8Pra7rLUhH"
      },
      "source": [
        "## Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sfZIbJBvsbsu"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(path + 'train.csv', index_col=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RqCjEWc624SU"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "Y_train = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xlz6n6jZCxss",
        "outputId": "f40d10a6-266d-4e58-840c-0f3bb5cac7ec"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "  inputs = feature_extractor(\n",
        "        [librosa.resample(np.asarray(torchaudio.load(audio_train[audio_train.index(path + 'train/' + str(d) + '.wav')])[0]).squeeze(0), 48_000, 16_000) for d in df_train['id'][:1]],\n",
        "        sampling_rate=16000, \n",
        "        return_tensors=\"pt\",             \n",
        "        max_length=int(feature_extractor.sampling_rate * max_duration), \n",
        "        truncation=True,\n",
        "        padding='max_length').to(device)\n",
        "  embeddings_concatenation = model(**inputs).embeddings\n",
        "  Y_train.append(df_train.loc[0,'label'])\n",
        "\n",
        "  for i in tqdm(range(1, len(df_train))):\n",
        "      inputs = feature_extractor(\n",
        "          [librosa.resample(np.asarray(torchaudio.load(audio_train[audio_train.index(path + 'train/' + str(d) + '.wav')])[0]).squeeze(0), 48_000, 16_000) for d in df_train['id'][i:i+1]],\n",
        "          sampling_rate=16000, \n",
        "          return_tensors=\"pt\",             \n",
        "          max_length=int(feature_extractor.sampling_rate * max_duration), \n",
        "          truncation=True,\n",
        "          padding='max_length').to(device)\n",
        "      embeddings = model(**inputs).embeddings\n",
        "      embeddings_concatenation = torch.cat((embeddings_concatenation, embeddings))\n",
        "      Y_train.append(df_train.loc[i,'label'])\n",
        "\n",
        "embeddings_train = torch.nn.functional.normalize(embeddings_concatenation, dim=-1).cpu()\n",
        "X_train = embeddings_train.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DvT_XFQYujn"
      },
      "outputs": [],
      "source": [
        "with open(path + 'X_train_30.txt', 'wb') as fp:\n",
        "    pickle.dump(X_train, fp)\n",
        "with open(path + 'Y_train_30.txt', 'wb') as fp:\n",
        "    pickle.dump(Y_train, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nKmKhlCdv1b5"
      },
      "outputs": [],
      "source": [
        "with open (path + 'X_train.txt', 'rb') as fp:\n",
        "    X_train = pickle.load(fp)\n",
        "with open (path + 'Y_train.txt', 'rb') as fp:\n",
        "    Y_train = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKBSfTjJxjcS",
        "outputId": "d71a07d0-136c-4437-81a2-42154537394e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8196\n",
            "8196\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train))\n",
        "print(len(Y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCLG_HdiLYKc"
      },
      "source": [
        "## Dev Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9XXerUTf26aA"
      },
      "outputs": [],
      "source": [
        "df_dev = pd.read_csv(path + 'dev.csv', index_col=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yHStFMJ264o"
      },
      "outputs": [],
      "source": [
        "X_dev = []\n",
        "Y_dev = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhIKupDiDrzC"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "  inputs = feature_extractor(\n",
        "        [librosa.resample(np.asarray(torchaudio.load(audio_dev[audio_dev.index(path + 'dev/a/' + str(d) + '.wav')])[0]).squeeze(0), 48_000, 16_000) for d in df_dev['id'][:1]],\n",
        "        sampling_rate=16000, \n",
        "        return_tensors=\"pt\",             \n",
        "        max_length=int(feature_extractor.sampling_rate * max_duration), \n",
        "        truncation=True,\n",
        "        padding='max_length').to(device)\n",
        "  embeddings_concatenation_dev = model(**inputs).embeddings\n",
        "  Y_dev.append(df_dev.loc[0,'label'])\n",
        "\n",
        "  for i in tqdm(range(1, len(df_dev))):\n",
        "      inputs = feature_extractor(\n",
        "          [librosa.resample(np.asarray(torchaudio.load(audio_dev[audio_dev.index(path + 'dev/a/' + str(d) + '.wav')])[0]).squeeze(0), 48_000, 16_000) for d in df_dev['id'][i:i+1]],\n",
        "          sampling_rate=16000, \n",
        "          return_tensors=\"pt\",             \n",
        "          max_length=int(feature_extractor.sampling_rate * max_duration), \n",
        "          truncation=True,\n",
        "          padding='max_length').to(device)\n",
        "      embeddings = model(**inputs).embeddings\n",
        "      embeddings_concatenation_dev = torch.cat((embeddings_concatenation_dev, embeddings))\n",
        "      Y_dev.append(df_dev.loc[i,'label'])\n",
        "\n",
        "embeddings_dev = torch.nn.functional.normalize(embeddings_concatenation_dev, dim=-1).cpu()\n",
        "X_dev = embeddings_dev.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyHNt5swYyoQ"
      },
      "outputs": [],
      "source": [
        "with open(path + 'X_dev_30.txt', 'wb') as fp:\n",
        "    pickle.dump(X_dev, fp)\n",
        "with open(path + 'Y_dev_30.txt', 'wb') as fp:\n",
        "    pickle.dump(Y_dev, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9EKWGbMh2x8l"
      },
      "outputs": [],
      "source": [
        "with open (path + 'X_dev.txt', 'rb') as fp:\n",
        "    X_dev = pickle.load(fp)\n",
        "with open (path + 'Y_dev.txt', 'rb') as fp:\n",
        "    Y_dev = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofBHJ9gzEYAi"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w15wbiLqLhdQ"
      },
      "source": [
        "## Compute Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RLRCJk5EU7c",
        "outputId": "bca24f46-8df9-4e0c-8e6a-d3835033c4d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: {0: 1.6261904761904762, 1: 0.7219873150105708}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "labels = df_train['label'].unique()\n",
        "weights = compute_class_weight('balanced', classes=labels, y=Y_train)\n",
        "class_weights = {k: v for k, v in zip(labels, weights)}\n",
        "\n",
        "print('Class weights:', class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ser_SkL2Lo0T"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D01DFs2cBul2"
      },
      "source": [
        "### Remove Nan Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7CkPX_mZvUb4"
      },
      "outputs": [],
      "source": [
        "def isNaN(num):\n",
        "  condition = (num != num)\n",
        "  if True in condition:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WrAjEJAC1rrX"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "original_stdout = sys.stdout    # Save a reference to the original standard output\n",
        "i = 0\n",
        "\n",
        "with open('/content/train_nan_values.txt', 'w') as f:\n",
        "\n",
        "  sys.stdout = f                # Change the standard output to the file just created\n",
        "\n",
        "  for x in X_train:\n",
        "    if isNaN(x) == True:\n",
        "      print(i)\n",
        "    i += 1\n",
        "    \n",
        "sys.stdout = original_stdout    # Reset the standard output to its original value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "BG2hG9vRwnvz"
      },
      "outputs": [],
      "source": [
        "nan_indexes = [40, 93, 491, 4463, 4488, 4489, 4495, 4506, 4714, 4771, 4835, 5031, 5044, 5049,\n",
        "               5207, 5212, 5219, 5225, 5374, 5399, 5434, 5458, 5505, 5507, 5560, 5564, 5582, 5586,\n",
        "               5595, 5619, 5626, 5632, 5646, 5656, 5662, 5668, 5673, 5675, 5678, 5686, 5698, 5702,\n",
        "               5704, 5719, 6667, 7788, 7832]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T07bpo4ozqYN"
      },
      "outputs": [],
      "source": [
        "X_train_1 = []\n",
        "Y_train_1 = []\n",
        "\n",
        "for i in range(0,len(X_train)):\n",
        "  if i not in nan_indexes:\n",
        "    X_train_1.append(X_train[i])\n",
        "    Y_train_1.append(Y_train[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbk1wK46B3xa"
      },
      "source": [
        "### Fit LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "cogfj14hEhWs"
      },
      "outputs": [],
      "source": [
        "LR_mosquito = LogisticRegression(class_weight=class_weights)\n",
        "LR_mosquito.fit(X_train_1, Y_train_1)\n",
        "Y_predicted = LR_mosquito.predict(X_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q1_Q4q7LtXv"
      },
      "source": [
        "### Compute Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHBfzRo0-Z4A",
        "outputId": "da65a281-882c-4859-875c-6b558b16d84c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weighted_F1_score: 0.4700736327832945\n",
            "macro_F1_score: 0.4580419791429545\n",
            "Classification report for classifier LogisticRegression(class_weight={0: 1.6261904761904762, 1: 0.7219873150105708}):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.19      0.27      1012\n",
            "           1       0.53      0.81      0.64      1153\n",
            "\n",
            "    accuracy                           0.52      2165\n",
            "   macro avg       0.50      0.50      0.46      2165\n",
            "weighted avg       0.50      0.52      0.47      2165\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('weighted_F1_score: ' + str(f1_score(Y_dev, Y_predicted, average='weighted')))\n",
        "print('macro_F1_score: ' + str(f1_score(Y_dev, Y_predicted, average='macro')))\n",
        "print(\n",
        "    f\"Classification report for classifier {LR_mosquito}:\\n\"\n",
        "    f\"{metrics.classification_report(Y_dev, Y_predicted)}\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG9YuNfTFwgS",
        "outputId": "7a53136f-f9f8-4126-b96c-dd672f08ab4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "roc_auc_score: 0.4958597437857591\n"
          ]
        }
      ],
      "source": [
        "print('roc_auc_score: ' + str(roc_auc_score(Y_dev, LR_mosquito.predict_proba(X_dev)[:, 1])))\n",
        "# print(roc_auc_score(Y_dev, LR_mosquito.decision_function(X_dev)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znYijcZlL0l7"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1ErezWoLHt0"
      },
      "outputs": [],
      "source": [
        "LR_mosquito_filename = path + 'LR_mosquito.sav'\n",
        "pickle.dump(LR_mosquito, open(LR_mosquito_filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYeEZlmJB_9o"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-26giu5SB_9o"
      },
      "source": [
        "### Remove Nan Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3OMk96O_B_9o"
      },
      "outputs": [],
      "source": [
        "def isNaN(num):\n",
        "  condition = (num != num)\n",
        "  if True in condition:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EfF9vkfxB_9p"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "original_stdout = sys.stdout    # Save a reference to the original standard output\n",
        "i = 0\n",
        "\n",
        "with open('/content/train_nan_values.txt', 'w') as f:\n",
        "\n",
        "  sys.stdout = f                # Change the standard output to the file just created\n",
        "\n",
        "  for x in X_train:\n",
        "    if isNaN(x) == True:\n",
        "      print(i)\n",
        "    i += 1\n",
        "    \n",
        "sys.stdout = original_stdout    # Reset the standard output to its original value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CcfPC7YEB_9p"
      },
      "outputs": [],
      "source": [
        "nan_indexes = [40, 93, 491, 4463, 4488, 4489, 4495, 4506, 4714, 4771, 4835, 5031, 5044, 5049,\n",
        "               5207, 5212, 5219, 5225, 5374, 5399, 5434, 5458, 5505, 5507, 5560, 5564, 5582, 5586,\n",
        "               5595, 5619, 5626, 5632, 5646, 5656, 5662, 5668, 5673, 5675, 5678, 5686, 5698, 5702,\n",
        "               5704, 5719, 6667, 7788, 7832]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3zgPKQduB_9p"
      },
      "outputs": [],
      "source": [
        "X_train_1 = []\n",
        "Y_train_1 = []\n",
        "\n",
        "for i in range(0,len(X_train)):\n",
        "  if i not in nan_indexes:\n",
        "    X_train_1.append(X_train[i])\n",
        "    Y_train_1.append(Y_train[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbGJRgqvB_9q"
      },
      "source": [
        "### Fit DT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "W6mwQxpdB_9q"
      },
      "outputs": [],
      "source": [
        "DT_mosquito = tree.DecisionTreeClassifier()\n",
        "DT_mosquito = DT_mosquito.fit(X_train_1, Y_train_1)\n",
        "Y_predicted = DT_mosquito.predict(X_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzul6hnqB_9r"
      },
      "source": [
        "### Compute Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NchzJLYB_9r",
        "outputId": "7c0cffb4-5475-46f9-882a-91de5bc165d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weighted_F1_score: 0.44542532954319286\n",
            "macro_F1_score: 0.4287391464123338\n",
            "Classification report for classifier DecisionTreeClassifier():\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.10      0.17      1012\n",
            "           1       0.54      0.93      0.68      1153\n",
            "\n",
            "    accuracy                           0.54      2165\n",
            "   macro avg       0.55      0.52      0.43      2165\n",
            "weighted avg       0.55      0.54      0.45      2165\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('weighted_F1_score: ' + str(f1_score(Y_dev, Y_predicted, average='weighted')))\n",
        "print('macro_F1_score: ' + str(f1_score(Y_dev, Y_predicted, average='macro')))\n",
        "print(\n",
        "    f\"Classification report for classifier {DT_mosquito}:\\n\"\n",
        "    f\"{metrics.classification_report(Y_dev, Y_predicted)}\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Qd0HX-B_9s",
        "outputId": "2a1dffa0-b6d1-422a-9ea6-2b7d67eca27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "roc_auc_score: 0.5166308718620269\n"
          ]
        }
      ],
      "source": [
        "print('roc_auc_score: ' + str(roc_auc_score(Y_dev, DT_mosquito.predict_proba(X_dev)[:, 1])))\n",
        "# print(roc_auc_score(Y_dev, LR_mosquito.decision_function(X_dev)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJAVnXP_B_9s"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfesBzX6B_9s"
      },
      "outputs": [],
      "source": [
        "DT_mosquito_filename = path + 'DT_mosquito.sav'\n",
        "pickle.dump(DT_mosquito, open(DT_mosquito_filename, 'wb'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "WavLMforXVectors - Mosquitos.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
